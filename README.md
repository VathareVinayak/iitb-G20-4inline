# ğŸ§  Mental State Monitoring Dashboard  

## ğŸ“Œ Project Overview  
This project was developed as part of the **IITB EdTech Internship 2025 (DYPCET, Track 1 - Educational Data Analysis)**.  
Our team **4InLine (Group ID: T1_G20)** worked on **Problem Statement 14: Building a Mental State Monitoring Dashboard**.  

The goal of this project is to create an **interactive real-time dashboard** that visualizes:  
- **Mental workload predictions** (Low / Medium / High)  
- **Accuracy probability** (likelihood of correct response)  
- **Emotion transitions** (e.g., Engaged â†’ Confused â†’ Neutral)  

This solution simulates real-time input from multimodal data sources (EEG, GSR, Eye-tracking, Facial expressions) and uses **pretrained ML models** to provide predictions.  

---

## ğŸš€ Features  
- ğŸ“Š **Mental Workload Panel** â€“ Gauge chart (Low/Medium/High workload levels).  
- ğŸ“ˆ **Accuracy Probability Panel** â€“ Real-time line chart with probability trends.  
- ğŸ­ **Emotion Transitions Panel** â€“ Sankey diagram or timeline visualization of emotional states.  
- ğŸ‘¤ **Participant Summary Panel** â€“ Snapshot of latest predictions with confidence values.  
- ğŸ”„ **Real-time updates** â€“ Simulated data replay at configurable refresh rates.  
- âš¡ **Scalable architecture** â€“ Easy to extend for multi-user support, alerts, and replay mode.  

---

## ğŸ› ï¸ Tech Stack  
- **Frontend/UI**: [Streamlit](https://streamlit.io/) 
- **Visualizations**: [Plotly](https://plotly.com/python/)  
- **Backend/Models**: Pretrained ML models (`.pkl` / `.pt`)  
- **Data Stream**: Simulated EEG, GSR, Eye-tracking, Facial expression signals  

---

## ğŸ“‚ Project Structure  
project/
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ EEG.csv
â”‚ â”œâ”€â”€ GSR.csv
â”‚ â”œâ”€â”€ EYE.csv
â”‚ â”œâ”€â”€ TIVA.csv
â”‚ â””â”€â”€ session_logs/
â”œâ”€â”€ models/
â”‚ â”œâ”€â”€ workload_model.pkl
â”‚ â”œâ”€â”€ accuracy_model.pkl
â”‚ â””â”€â”€ emotion_model.pkl
â”œâ”€â”€ app/
â”‚ â”œâ”€â”€ dashboard.py # Main Streamlit/Dash application
â”‚ â”œâ”€â”€ utils.py # Data stream + feature extraction
â”‚ â””â”€â”€ components.py # Plotting helpers
â””â”€â”€ README.md

ğŸ“Š Sample Workflow

1. Load pretrained models (workload_model.pkl, accuracy_model.pkl, emotion_model.pkl).
2. Stream simulated multimodal data (EEG, GSR, Eye, Facial expressions).
3. Generate predictions for workload, accuracy, and emotion states.
4. Update visualizations in real-time on the dashboard.

ğŸ”— Resources & Drive Link

Since the models and datasets may be large, they are stored externally.
ğŸ‘‰ [Click here to access project files (Google Drive)](https://drive.google.com/drive/folders/1ceLALHU3k7zsFGPZ8IhNIpAbEuE6Ihah)

ğŸ‘¥ Team - Group 4InLine (T1_G20)

Group Members: 1. Aakash Mohole
               2. Vinayak Vathare
               3. Shreyash Shetty
               
Faculty Mentor: Mrs. T.V. Deokar

Department: CSE (Data Science)
